@online{hame_shapefile_2019,
  title = {Shapefile vs. {GeoJSON} vs. {GeoPackage}},
  url = {https://feed.terramonitor.com/shapefile-vs-geopackage-vs-geojson/},
  abstract = {What if you were given the option to choose your {GIS} file format freely, is there one format which is technically superior to the others?},
  titleaddon = {Terramonitor Feed},
  author = {HÃ¤me, Juho},
  urldate = {2019-08-29},
  date = {2019-07-03},
  langid = {english},
  file = {Snapshot:/home/jakobgm/Zotero/storage/4QIB3JXR/2019 - Shapefile vs. GeoJSON vs. GeoPackage.html:text/html}
}

@article{lidar_meteorology_1966,
  author = {Northend,C. A.  and Honey,R. C.  and Evans,W. E. },
  title = {Laser Radar (Lidar) for Meteorological Observations},
  journal = {Review of Scientific Instruments},
  volume = {37},
  number = {4},
  pages = {393-400},
  year = {1966},
  doi = {10.1063/1.1720199},

  URL = { 
          https://doi.org/10.1063/1.1720199
      
  },
  eprint = { 
          https://doi.org/10.1063/1.1720199
      
  }
}

@article{lidar_forestry_2000,
  author = {Dubayah, Ralph O. and Drake, Jason B.},
  title = "{Lidar Remote Sensing for Forestry}",
  journal = {Journal of Forestry},
  volume = {98},
  number = {6},
  pages = {44-46},
  year = {2000},
  month = {06},
  abstract = "{Lidar remote sensing, which directly measures vertical forest structure, is a breakthrough technology with many forestry applications. Using the laser light equivalent of radar, lidar instruments accurately estimate such important forest structural characteristics as canopy heights,
  stand volume, basal area, and above-ground biomass. And because subcanopy vegetation height is a function of species composition, climate, and site quality, the results can be used for land cover classification, habitat mapping, and forest wildlife management.}",
  issn = {0022-1201},
  doi = {10.1093/jof/98.6.44},
  url = {https://doi.org/10.1093/jof/98.6.44},
  eprint = {http://oup.prod.sis.lan/jof/article-pdf/98/6/44/22558157/jof0044.pdf},
}

@article{
  lidar_self_driving_2018,
  title={Lidar for self-driving cars},
  author={Hecht, Jeff},
  journal={Optics and Photonics News},
  volume={29},
  number={1},
  pages={26--33},
  year={2018},
  publisher={Optical Society of America}
}

@article{lidar_flood_2013,
  title={Evaluating scale and roughness effects in urban flood modelling using terrestrial LIDAR data},
  author={Ozdemir, H and Sampson, C and de Almeida, Gustavo AM and Bates, PD},
  journal={Hydrology and Earth System Sciences},
  volume={10},
  pages={5903--5942},
  year={2013}
}

@online{wiki:europe_utm_zones,
 author = "Wikimedia Commons",
 title = "File:LA2-Europe-UTM-zones.png --- Wikimedia Commons{,} the free media repository",
 year = "2015",
 url = "https://commons.wikimedia.org/w/index.php?title=File:LA2-Europe-UTM-zones.png&oldid=146057239",
 urldate = {2019-11-04}
}

@book{map_projections_1987,
  title={Map projections--A working manual},
  author={Snyder, John Parr},
  volume={1395},
  year={1987},
  publisher={US Government Printing Office}
}

@online{vrt_schema_2015,
 author = "Even Rouault",
 title = "File:gdalvrt.xsd --- XML Schema for GDAL VRT files.",
 year = "2015",
 url = "https://raw.githubusercontent.com/OSGeo/gdal/master/gdal/data/gdalvrt.xsd",
 urldate = {2019-11-07}
}

@manual{trondheim_lidar_2017,
 author = "Terratec AS",
 institution = "Trondheim kommune",
 title = "Rapport for laserskanning",
 year = "2017",
 note = "Comissioned by Trondheim kommune"
}

@manual{ortofoto_in_norway_2003,
 author = "Statens kartverk",
 title = "Produktspesifikasjon for ortofoto i Norge",
 year = "2003",
 url = "https://register.geonorge.no/data/documents/produktspesifikasjoner_Digitale%20ortofoto_v1_ortofoto-spesifikasjon-v1-2003_.pdf"
}

@online{trondheim_ortophoto_2017,
 author = "Statens kartverk",
 title = "Ortofoto Trondheim 2017",
 year = "2018",
 month = "May",
 url = "https://kartkatalog.geonorge.no/metadata/cd105955-6507-416f-86d2-6d95c1b74278",
 urldate = {2019-11-07}
}

@article{input_normalization_1997,
  author={J. {Sola} and J. {Sevilla}},
  journal={IEEE Transactions on Nuclear Science},
  title={Importance of input data normalization for the application of neural networks to complex industrial problems},
  year={1997},
  volume={44},
  number={3},
  pages={1464-1468},
  keywords={backpropagation;neural nets;nuclear engineering computing;fission reactor safety;identification;parameter estimation;input data normalization;estimation;complex industrial problems;artificial intelligence;backpropagation neural networks;identification;nuclear power plants;backpropagation training process;input data pretreatment;PWR nuclear power plant;Neural networks;Artificial neural networks;Power generation;Backpropagation;Inductors;Artificial intelligence;Industrial training;Power measurement;Multilayer perceptrons;Parameter estimation},
  doi={10.1109/23.589532},
  ISSN={},
  month={June}
}
  
@inproceedings{image_recognition,
  title={Feature Extraction and Image Recognition with Convolutional Neural Networks},
  author={Liu, Yu Han},
  booktitle={Journal of Physics: Conference Series},
  volume={1087},
  number={6},
  pages={062032},
  year={2018},
  organization={IOP Publishing}
}

@book{computer_vision_history,
  title={Computer vision: algorithms and applications},
  author={Szeliski, Richard},
  year={2010},
  publisher={Springer Science \& Business Media}
}

@book{goodfellow,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@misc{batch-normalization,
  title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author={Sergey Ioffe and Christian Szegedy},
  year={2015},
  eprint={1502.03167},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@book{dive-into-deep-learning,
  title={Dive into Deep Learning},
  author={Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},
  edition={Release 0.7.0},
  url={https://d2l.ai},
  urldate={2019-11-28}
}

% First book in Visual Intelligence syllabus
@misc{visint-cnn,
  publisher = {Pearson},
  isbn = {9781292223049},
  year = {2018},
  title = {Digital Image Processing},
  edition = {4th ed.},
  language = {eng},
  address = {New York},
  author = {Gonzalez, Rafael C},
  keywords = {Digital bildebehandling; Bildebehandling; digital bildebehandling},
}

@misc{cnn-translational-invariance,
  title={Quantifying Translation-Invariance in Convolutional Neural Networks},
  author={Eric Kauderer-Abrams},
  year={2017},
  eprint={1801.01450},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

% Original "Universal Approximation Theorem" paper, using sigmoid function.
@article{uat-sigmoid,
  title={Approximations by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of Control, Signals and Systems},
  volume={2},
  pages={183--192},
  year={1989}
}

% Follow-up "Universal Approximation Theorem" paper, using nonpolynomial activation functions
@article{uat-nonpolynomial,
  title={Multilayer feedforward networks with a nonpolynomial activation function can approximate any function},
  author={Leshno, Moshe and Lin, Vladimir Ya and Pinkus, Allan and Schocken, Shimon},
  journal={Neural networks},
  volume={6},
  number={6},
  pages={861--867},
  year={1993},
  publisher={Elsevier}
}

% Original ReLU paper
% https://www.nature.com/articles/35016072
@article{relu-original-paper,
  title={Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit},
  author={Hahnloser, Richard HR and Sarpeshkar, Rahul and Mahowald, Misha A and Douglas, Rodney J and Seung, H Sebastian},
  journal={Nature},
  volume={405},
  number={6789},
  pages={947},
  year={2000},
  publisher={Nature Publishing Group}
}

% Original artificial perceptron paper
% https://psycnet.apa.org/fulltext/1959-09865-001.pdf
@article{rosenblatt-perceptron-1958,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Rosenblatt, Frank},
  journal={Psychological review},
  volume={65},
  number={6},
  pages={386},
  year={1958},
  publisher={American Psychological Association}
}

% Popularity of ReLU function noted on page 438 in lower right
% Gives a good overview of several deep learning topics, including CNNs
% https://www.nature.com/articles/nature14539.pdf
@article{relu-popularity,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

% Explains how ReLU activation function is an improvement over sigmoid
% http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf
@inproceedings{relu-better-than-sigmoid,
  title={Deep sparse rectifier neural networks},
  author={Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={315--323},
  year={2011}
}

% Can be used to cite the introduction of dropout as a concept
% https://arxiv.org/pdf/1207.0580.pdf
@article{dropout-original-paper,
    title={Improving neural networks by preventing co-adaptation of feature detectors},
    author={Geoffrey E. Hinton and Nitish Srivastava and Alex Krizhevsky and Ilya Sutskever and Ruslan R. Salakhutdinov},
    year={2012},
    eprint={1207.0580},
    journal={arXiv preprint arXiv:1207.0580},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}

% Overview of dropout techniques. Also describes dropout in CNNs.
% Describes that batch normalization is considered a regularization technique as well.
% https://arxiv.org/pdf/1904.13310.pdf
@article{dropout-cnn,
    title={Survey of Dropout Methods for Deep Neural Networks},
    author={Alex Labach and Hojjat Salehinejad and Shahrokh Valaee},
    year={2019},
    eprint={1904.13310},
    journal={arXiv preprint arXiv:1904.13310},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}

% CNN dropout technique, removing part of input image
% https://arxiv.org/pdf/1708.04552.pdf
@article{dropout-cutout,
    title={Improved Regularization of Convolutional Neural Networks with Cutout},
    author={Terrance DeVries and Graham W. Taylor},
    year={2017},
    eprint={1708.04552},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

% CNN dropout technique, dropping entire layers such that they simple forward their output
@InProceedings{dropout-stochastic-depth,
    author="Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian Q.",
    editor="Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max",
    title="Deep Networks with Stochastic Depth",
    booktitle="Computer Vision -- ECCV 2016",
    year="2016",
    publisher="Springer International Publishing",
    address="Cham",
    pages="646--661",
    isbn="978-3-319-46493-0"
}

% Paper starting work on dropout in convolutional layers, introducing max-pooling dropout,
% a.k.a. probabilistic weighted pooling
% https://www.sciencedirect.com/science/article/pii/S0893608015001446
@article{max-pooling-dropout,
    title = "Towards dropout training for convolutional neural networks",
    journal = "Neural Networks",
    volume = "71",
    pages = "1--10",
    year = "2015",
    issn = "0893-6080",
    doi = "https://doi.org/10.1016/j.neunet.2015.07.007",
    url = "http://www.sciencedirect.com/science/article/pii/S0893608015001446",
    author = "Haibing Wu and Xiaodong Gu",
    keywords = "Deep learning, Convolutional neural networks, Max-pooling dropout"
}

% Paper showing that the order of batch normalization and dropout is really important
% https://arxiv.org/pdf/1904.03392.pdf
@article{dropout-order,
    title={Effective and Efficient Dropout for Deep Convolutional Neural Networks},
    author={Shaofeng Cai and Yao Shu and Wei Wang and Meihui Zhang and Gang Chen and Beng Chin Ooi},
    year={2019},
    eprint={1904.03392},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

% Deep learning image segmentation overview
% https://arxiv.org/pdf/1704.06857.pdf
@article{segmentation-overview,
    title={A Review on Deep Learning Techniques Applied to Semantic Segmentation},
    author={Alberto Garcia-Garcia and Sergio Orts-Escolano and Sergiu Oprea and Victor Villena-Martinez and Jose Garcia-Rodriguez},
    year={2017},
    eprint={1704.06857},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

% Recent progress made in segmentation (2018)
% https://arxiv.org/pdf/1809.10198.pdf
@article{segmentation-progress,
   title={Recent progress in semantic image segmentation},
   volume={52},
   ISSN={1573-7462},
   url={http://dx.doi.org/10.1007/s10462-018-9641-3},
   DOI={10.1007/s10462-018-9641-3},
   number={2},
   journal={Artificial Intelligence Review},
   publisher={Springer Science and Business Media LLC},
   author={Liu, Xiaolong and Deng, Zhidong and Yang, Yuhan},
   year={2018},
   month={Jun},
   pages={1089â1106}
}

% Use of FCNN for semantic segmentation
% https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf
@InProceedings{segmentation-fcnn,
  author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  title = {Fully Convolutional Networks for Semantic Segmentation},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2015}
}

% SegNet architecture
% https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7803544
@article{segmentation-segnet,
  author={V. {Badrinarayanan} and A. {Kendall} and R. {Cipolla}},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title={SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation},
  year={2017},
  volume={39},
  number={12},
  pages={2481-2495},
  doi={10.1109/TPAMI.2016.2644615},
  ISSN={1939-3539},
  month={Dec}
}

% U-Net architecture
% https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28
@InProceedings{segmentation-unet,
  author="Ronneberger, Olaf
  and Fischer, Philipp
  and Brox, Thomas",
  editor="Navab, Nassir
  and Hornegger, Joachim
  and Wells, William M.
  and Frangi, Alejandro F.",
  title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
  booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
  year="2015",
  publisher="Springer International Publishing",
  address="Cham",
  pages="234--241",
  isbn="978-3-319-24574-4"
}

% Mask R-CNN architecture
% http://openaccess.thecvf.com/content_ICCV_2017/papers/He_Mask_R-CNN_ICCV_2017_paper.pdf
@InProceedings{segmentation-mask-r-cnn,
  author = {He, Kaiming and Gkioxari, Georgia and Dollar, Piotr and Girshick, Ross},
  title = {Mask R-CNN},
  booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
  month = {Oct},
  year = {2017}
}

% SegCaps architecture
% https://arxiv.org/pdf/1804.04241.pdf
@article{segmentation-segcaps,
    title={Capsules for Object Segmentation},
    author={Rodney LaLonde and Ulas Bagci},
    year={2018},
    eprint={1804.04241},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

% Unification of instance and semantic segmentation, probably not relevant
% http://openaccess.thecvf.com/content_CVPR_2019/papers/Kirillov_Panoptic_Feature_Pyramid_Networks_CVPR_2019_paper.pdf
@InProceedings{segmentation-panoptic-feature-pyramid,
  author = {Kirillov, Alexander and Girshick, Ross and He, Kaiming and Dollar, Piotr},
  title = {Panoptic Feature Pyramid Networks},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2019}
}

% Can be used to explain that depth can be inferred from RGB images
% https://arxiv.org/pdf/1907.10326.pdf
@article{depth-estimation,
  title={From Big to Small: Multi-Scale Local Planar Guidance for Monocular Depth Estimation},
  author={Jin Han Lee and Myung-Kyu Han and Dong Wook Ko and Il Hong Suh},
  year={2019},
  eprint={1907.10326},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}
