@online{hame_shapefile_2019,
  title = {Shapefile vs. {GeoJSON} vs. {GeoPackage}},
  url = {https://feed.terramonitor.com/shapefile-vs-geopackage-vs-geojson/},
  abstract = {What if you were given the option to choose your {GIS} file format freely, is there one format which is technically superior to the others?},
  titleaddon = {Terramonitor Feed},
  author = {HÃ¤me, Juho},
  urldate = {2019-08-29},
  date = {2019-07-03},
  langid = {english},
  file = {Snapshot:/home/jakobgm/Zotero/storage/4QIB3JXR/2019 - Shapefile vs. GeoJSON vs. GeoPackage.html:text/html}
}

@article{lidar_meteorology_1966,
  author = {Northend,C. A.  and Honey,R. C.  and Evans,W. E. },
  title = {Laser Radar (Lidar) for Meteorological Observations},
  journal = {Review of Scientific Instruments},
  volume = {37},
  number = {4},
  pages = {393-400},
  year = {1966},
  doi = {10.1063/1.1720199},

  URL = { 
          https://doi.org/10.1063/1.1720199
      
  },
  eprint = { 
          https://doi.org/10.1063/1.1720199
      
  }
}

@article{lidar_forestry_2000,
  author = {Dubayah, Ralph O. and Drake, Jason B.},
  title = "{Lidar Remote Sensing for Forestry}",
  journal = {Journal of Forestry},
  volume = {98},
  number = {6},
  pages = {44-46},
  year = {2000},
  month = {06},
  abstract = "{Lidar remote sensing, which directly measures vertical forest structure, is a breakthrough technology with many forestry applications. Using the laser light equivalent of radar, lidar instruments accurately estimate such important forest structural characteristics as canopy heights,
  stand volume, basal area, and above-ground biomass. And because subcanopy vegetation height is a function of species composition, climate, and site quality, the results can be used for land cover classification, habitat mapping, and forest wildlife management.}",
  issn = {0022-1201},
  doi = {10.1093/jof/98.6.44},
  url = {https://doi.org/10.1093/jof/98.6.44},
  eprint = {http://oup.prod.sis.lan/jof/article-pdf/98/6/44/22558157/jof0044.pdf},
}

@article{
  lidar_self_driving_2018,
  title={Lidar for self-driving cars},
  author={Hecht, Jeff},
  journal={Optics and Photonics News},
  volume={29},
  number={1},
  pages={26--33},
  year={2018},
  publisher={Optical Society of America}
}

@article{lidar_flood_2013,
  title={Evaluating scale and roughness effects in urban flood modelling using terrestrial LIDAR data},
  author={Ozdemir, H and Sampson, C and de Almeida, Gustavo AM and Bates, PD},
  journal={Hydrology and Earth System Sciences},
  volume={10},
  pages={5903--5942},
  year={2013}
}

@online{wiki:europe_utm_zones,
 author = "Wikimedia Commons",
 title = "File:LA2-Europe-UTM-zones.png --- Wikimedia Commons{,} the free media repository",
 year = "2015",
 url = "https://commons.wikimedia.org/w/index.php?title=File:LA2-Europe-UTM-zones.png&oldid=146057239",
 urldate = {2019-11-04}
}

@book{map_projections_1987,
  title={Map projections--A working manual},
  author={Snyder, John Parr},
  volume={1395},
  year={1987},
  publisher={US Government Printing Office}
}

@online{vrt_schema_2015,
 author = "Even Rouault",
 title = "File:gdalvrt.xsd --- XML Schema for GDAL VRT files.",
 year = "2015",
 url = "https://raw.githubusercontent.com/OSGeo/gdal/master/gdal/data/gdalvrt.xsd",
 urldate = {2019-11-07}
}

@manual{trondheim_lidar_2017,
 author = "Terratec AS",
 institution = "Trondheim kommune",
 title = "Rapport for laserskanning",
 year = "2017",
 note = "Comissioned by Trondheim kommune"
}

@manual{ortofoto_in_norway_2003,
 author = "Statens kartverk",
 title = "Produktspesifikasjon for ortofoto i Norge",
 year = "2003",
 url = "https://register.geonorge.no/data/documents/produktspesifikasjoner_Digitale%20ortofoto_v1_ortofoto-spesifikasjon-v1-2003_.pdf"
}

@online{trondheim_ortophoto_2017,
 author = "Statens kartverk",
 title = "Ortofoto Trondheim 2017",
 year = "2018",
 month = "May",
 url = "https://kartkatalog.geonorge.no/metadata/cd105955-6507-416f-86d2-6d95c1b74278",
 urldate = {2019-11-07}
}

@article{input_normalization_1997,
  author={J. {Sola} and J. {Sevilla}},
  journal={IEEE Transactions on Nuclear Science},
  title={Importance of input data normalization for the application of neural networks to complex industrial problems},
  year={1997},
  volume={44},
  number={3},
  pages={1464-1468},
  keywords={backpropagation;neural nets;nuclear engineering computing;fission reactor safety;identification;parameter estimation;input data normalization;estimation;complex industrial problems;artificial intelligence;backpropagation neural networks;identification;nuclear power plants;backpropagation training process;input data pretreatment;PWR nuclear power plant;Neural networks;Artificial neural networks;Power generation;Backpropagation;Inductors;Artificial intelligence;Industrial training;Power measurement;Multilayer perceptrons;Parameter estimation},
  doi={10.1109/23.589532},
  ISSN={},
  month={June}
}
  
@inproceedings{image_recognition,
  title={Feature Extraction and Image Recognition with Convolutional Neural Networks},
  author={Liu, Yu Han},
  booktitle={Journal of Physics: Conference Series},
  volume={1087},
  number={6},
  pages={062032},
  year={2018},
  organization={IOP Publishing}
}

@book{computer_vision_history,
  title={Computer vision: algorithms and applications},
  author={Szeliski, Richard},
  year={2010},
  publisher={Springer Science \& Business Media}
}

@book{goodfellow,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@misc{batch-normalization,
  title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author={Sergey Ioffe and Christian Szegedy},
  year={2015},
  eprint={1502.03167},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@book{dive-into-deep-learning,
  title={Dive into Deep Learning},
  author={Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},
  edition={Release 0.7.0},
  url={https://d2l.ai},
  urldate={2019-11-28}
}

% First book in Visual Intelligence syllabus
@misc{visint-cnn,
  publisher = {Pearson},
  isbn = {9781292223049},
  year = {2018},
  title = {Digital Image Processing},
  edition = {4th ed.},
  language = {eng},
  address = {New York},
  author = {Gonzalez, Rafael C},
  keywords = {Digital bildebehandling; Bildebehandling; digital bildebehandling},
}

@misc{cnn-translational-invariance,
  title={Quantifying Translation-Invariance in Convolutional Neural Networks},
  author={Eric Kauderer-Abrams},
  year={2017},
  eprint={1801.01450},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

% Original "Universal Approximation Theorem" paper, using sigmoid function.
@article{uat-sigmoid,
  title={Approximations by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of Control, Signals and Systems},
  volume={2},
  pages={183--192},
  year={1989}
}

% Follow-up "Universal Approximation Theorem" paper, using nonpolynomial activation functions
@article{uat-nonpolynomial,
  title={Multilayer feedforward networks with a nonpolynomial activation function can approximate any function},
  author={Leshno, Moshe and Lin, Vladimir Ya and Pinkus, Allan and Schocken, Shimon},
  journal={Neural networks},
  volume={6},
  number={6},
  pages={861--867},
  year={1993},
  publisher={Elsevier}
}

% Original ReLU paper
% https://www.nature.com/articles/35016072
@article{relu-original-paper,
  title={Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit},
  author={Hahnloser, Richard HR and Sarpeshkar, Rahul and Mahowald, Misha A and Douglas, Rodney J and Seung, H Sebastian},
  journal={Nature},
  volume={405},
  number={6789},
  pages={947},
  year={2000},
  publisher={Nature Publishing Group}
}

% Original artificial perceptron paper
% https://psycnet.apa.org/fulltext/1959-09865-001.pdf
@article{rosenblatt-perceptron-1958,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Rosenblatt, Frank},
  journal={Psychological review},
  volume={65},
  number={6},
  pages={386},
  year={1958},
  publisher={American Psychological Association}
}

% Popularity of ReLU function noted on page 438 in lower right
% Gives a good overview of several deep learning topics, including CNNs
% https://www.nature.com/articles/nature14539.pdf
@article{relu-popularity,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

% Explains how ReLU activation function is an improvement over sigmoid
% http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf
@inproceedings{relu-better-than-sigmoid,
  title={Deep sparse rectifier neural networks},
  author={Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={315--323},
  year={2011}
}

% Can be used to cite the introduction of dropout as a concept
% https://arxiv.org/pdf/1207.0580.pdf
@article{dropout-original-paper,
    title={Improving neural networks by preventing co-adaptation of feature detectors},
    author={Geoffrey E. Hinton and Nitish Srivastava and Alex Krizhevsky and Ilya Sutskever and Ruslan R. Salakhutdinov},
    year={2012},
    eprint={1207.0580},
    journal={arXiv preprint arXiv:1207.0580},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}

% Overview of dropout techniques. Also describes dropout in CNNs.
% Describes that batch normalization is considered a regularization technique as well.
% https://arxiv.org/pdf/1904.13310.pdf
@article{dropout-cnn,
    title={Survey of Dropout Methods for Deep Neural Networks},
    author={Alex Labach and Hojjat Salehinejad and Shahrokh Valaee},
    year={2019},
    eprint={1904.13310},
    journal={arXiv preprint arXiv:1904.13310},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}

% CNN dropout technique, removing part of input image
% https://arxiv.org/pdf/1708.04552.pdf
@article{dropout-cutout,
    title={Improved Regularization of Convolutional Neural Networks with Cutout},
    author={Terrance DeVries and Graham W. Taylor},
    year={2017},
    eprint={1708.04552},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

% CNN dropout technique, dropping entire layers such that they simple forward their output
@InProceedings{dropout-stochastic-depth,
    author="Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian Q.",
    editor="Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max",
    title="Deep Networks with Stochastic Depth",
    booktitle="Computer Vision -- ECCV 2016",
    year="2016",
    publisher="Springer International Publishing",
    address="Cham",
    pages="646--661",
    isbn="978-3-319-46493-0"
}

% Paper starting work on dropout in convolutional layers, introducing max-pooling dropout,
% a.k.a. probabilistic weighted pooling
% https://www.sciencedirect.com/science/article/pii/S0893608015001446
@article{max-pooling-dropout,
    title = "Towards dropout training for convolutional neural networks",
    journal = "Neural Networks",
    volume = "71",
    pages = "1--10",
    year = "2015",
    issn = "0893-6080",
    doi = "https://doi.org/10.1016/j.neunet.2015.07.007",
    url = "http://www.sciencedirect.com/science/article/pii/S0893608015001446",
    author = "Haibing Wu and Xiaodong Gu",
    keywords = "Deep learning, Convolutional neural networks, Max-pooling dropout"
}

% Paper showing that the order of batch normalization and dropout is really important
% https://arxiv.org/pdf/1904.03392.pdf
@article{dropout-order,
    title={Effective and Efficient Dropout for Deep Convolutional Neural Networks},
    author={Shaofeng Cai and Yao Shu and Wei Wang and Meihui Zhang and Gang Chen and Beng Chin Ooi},
    year={2019},
    eprint={1904.03392},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

% Deep learning image segmentation overview
% https://arxiv.org/pdf/1704.06857.pdf
@article{segmentation-overview,
    title={A Review on Deep Learning Techniques Applied to Semantic Segmentation},
    author={Alberto Garcia-Garcia and Sergio Orts-Escolano and Sergiu Oprea and Victor Villena-Martinez and Jose Garcia-Rodriguez},
    year={2017},
    eprint={1704.06857},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

% Recent progress made in segmentation (2018)
% https://arxiv.org/pdf/1809.10198.pdf
@article{segmentation-progress,
   title={Recent progress in semantic image segmentation},
   volume={52},
   ISSN={1573-7462},
   url={http://dx.doi.org/10.1007/s10462-018-9641-3},
   DOI={10.1007/s10462-018-9641-3},
   number={2},
   journal={Artificial Intelligence Review},
   publisher={Springer Science and Business Media LLC},
   author={Liu, Xiaolong and Deng, Zhidong and Yang, Yuhan},
   year={2018},
   month={Jun},
   pages={1089â1106}
}

% Use of FCNN for semantic segmentation
% https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf
@InProceedings{segmentation-fcnn,
  author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  title = {Fully Convolutional Networks for Semantic Segmentation},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2015}
}

% SegNet architecture
% https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7803544
@article{segmentation-segnet,
  author={V. {Badrinarayanan} and A. {Kendall} and R. {Cipolla}},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title={SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation},
  year={2017},
  volume={39},
  number={12},
  pages={2481-2495},
  doi={10.1109/TPAMI.2016.2644615},
  ISSN={1939-3539},
  month={Dec}
}

% U-Net architecture
% https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28
@InProceedings{segmentation-unet,
  author="Ronneberger, Olaf
  and Fischer, Philipp
  and Brox, Thomas",
  editor="Navab, Nassir
  and Hornegger, Joachim
  and Wells, William M.
  and Frangi, Alejandro F.",
  title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
  booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
  year="2015",
  publisher="Springer International Publishing",
  address="Cham",
  pages="234--241",
  isbn="978-3-319-24574-4"
}

% Mask R-CNN architecture
% http://openaccess.thecvf.com/content_ICCV_2017/papers/He_Mask_R-CNN_ICCV_2017_paper.pdf
@InProceedings{segmentation-mask-r-cnn,
  author = {He, Kaiming and Gkioxari, Georgia and Dollar, Piotr and Girshick, Ross},
  title = {Mask R-CNN},
  booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
  month = {Oct},
  year = {2017}
}

% SegCaps architecture
% https://arxiv.org/pdf/1804.04241.pdf
@article{segmentation-segcaps,
    title={Capsules for Object Segmentation},
    author={Rodney LaLonde and Ulas Bagci},
    year={2018},
    eprint={1804.04241},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

% Unification of instance and semantic segmentation, probably not relevant
% http://openaccess.thecvf.com/content_CVPR_2019/papers/Kirillov_Panoptic_Feature_Pyramid_Networks_CVPR_2019_paper.pdf
@InProceedings{segmentation-panoptic-feature-pyramid,
  author = {Kirillov, Alexander and Girshick, Ross and He, Kaiming and Dollar, Piotr},
  title = {Panoptic Feature Pyramid Networks},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2019}
}

% Can be used to explain that depth can be inferred from RGB images
% https://arxiv.org/pdf/1907.10326.pdf
@article{depth-estimation,
  title={From Big to Small: Multi-Scale Local Planar Guidance for Monocular Depth Estimation},
  author={Jin Han Lee and Myung-Kyu Han and Dong Wook Ko and Il Hong Suh},
  year={2019},
  eprint={1907.10326},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

% AlexNet-paper. First deep learning paper for classification tasks.
% http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf
@incollection{segmentation-alexnet,
  title = {ImageNet Classification with Deep Convolutional Neural Networks},
  author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle = {Advances in Neural Information Processing Systems 25},
  editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
  pages = {1097--1105},
  year = {2012},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}

% Original VGG-16 architecture
% https://arxiv.org/pdf/1409.1556.pdf
@article{vgg-16,
  title={Very Deep Convolutional Networks for Large-Scale Image Recognition},
  author={Karen Simonyan and Andrew Zisserman},
  year={2014},
  eprint={1409.1556},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

% GoogLeNet
% https://arxiv.org/pdf/1409.4842.pdf
@article{googlenet,
  title={Going Deeper with Convolutions},
  author={Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
  year={2014},
  eprint={1409.4842},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

% ResNet
% http://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf
@InProceedings{resnet,
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title = {Deep Residual Learning for Image Recognition},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2016}
}

% R-CNN
% http://openaccess.thecvf.com/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf
@InProceedings{r-cnn,
  author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  title = {Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2014}
} 

% Fast R-CNN
% https://arxiv.org/pdf/1504.08083.pdf
@article{fast-r-cnn,
  title={Fast R-CNN},
  author={Ross Girshick},
  year={2015},
  eprint={1504.08083},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

% Faster R-CNN
% http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf
@incollection{faster-r-cnn,
  title = {Faster R-{CNN}: Towards Real-Time Object Detection with Region Proposal Networks},
  url = {http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf},
  pages = {91--99},
  booktitle = {Advances in Neural Information Processing Systems 28},
  publisher = {Curran Associates, Inc.},
  author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  editor = {Cortes, C. and Lawrence, N. D. and Lee, D. D. and Sugiyama, M. and Garnett, R.},
  date = {2015}
}

% Mask R-CNN
% http://openaccess.thecvf.com/content_ICCV_2017/papers/He_Mask_R-CNN_ICCV_2017_paper.pdf
@InProceedings{mask-r-cnn,
  author = {He, Kaiming and Gkioxari, Georgia and Dollar, Piotr and Girshick, Ross},
  title = {Mask R-CNN},
  booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
  month = {Oct},
  year = {2017}
}

" Dynamic routing between capsules (Original Capsule theory)
" http://papers.nips.cc/paper/6975-dynamic-routing-between-capsules.pdf
@incollection{capsules,
  title = {Dynamic Routing Between Capsules},
  url = {http://papers.nips.cc/paper/6975-dynamic-routing-between-capsules.pdf},
  pages = {3856--3866},
  booktitle = {Advances in Neural Information Processing Systems 30},
  publisher = {Curran Associates, Inc.},
  author = {Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey E},
  editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  date = {2017}
}

% Explaining segmentation losses derived from metrics
% Also explains the discrepancy between BCEL and common metrics
% Found no significant difference between metric-sensitive losses w.r.t. Dice or Jaccard [p. 98]
% https://link.springer.com/chapter/10.1007/978-3-030-32245-8_11
% https://link.springer.com/content/pdf/10.1007%2F978-3-030-32245-8.pdf
@InProceedings{soft-losses,
  author="Bertels, Jeroen and Eelbode, Tom and Berman, Maxim and Vandermeulen, Dirk and Maes, Frederik and Bisschops, Raf and Blaschko, Matthew B.", editor="Shen, Dinggang and Liu, Tianming and Peters, Terry M.  and Staib, Lawrence H.  and Essert, Caroline and Zhou, Sean and Yap, Pew-Thian and Khan, Ali",
  title="Optimizing the Dice Score and Jaccard Index for Medical Image Segmentation: Theory and Practice",
  booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2019",
  year="2019",
  publisher="Springer International Publishing",
  address="Cham",
  pages="92--100",
  isbn="978-3-030-32245-8"
}

% Soft dice loss article, comparing different losses derived from metrics
% https://arxiv.org/pdf/1707.03237.pdf
@article{generalized-dice-overlap,
   title={Generalised Dice Overlap as a Deep Learning Loss Function for Highly Unbalanced Segmentations},
   ISBN={9783319675589},
   ISSN={1611-3349},
   url={http://dx.doi.org/10.1007/978-3-319-67558-9_28},
   DOI={10.1007/978-3-319-67558-9_28},
   journal={Lecture Notes in Computer Science},
   publisher={Springer International Publishing},
   author={Sudre, Carole H. and Li, Wenqi and Vercauteren, Tom and Ourselin, Sebastien and Jorge Cardoso, M.},
   year={2017},
   pages={240â248}
}

% Original soft dice loss proposal
% https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7785132
@inproceedings{original-soft-dice-loss,
  author={F. {Milletari} and N. {Navab} and S. {Ahmadi}},
  booktitle={2016 Fourth International Conference on 3D Vision (3DV)},
  title={V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation},
  year={2016},
  volume={},
  number={},
  pages={565-571},
  doi={10.1109/3DV.2016.79},
  ISSN={null},
  month={Oct}
}
