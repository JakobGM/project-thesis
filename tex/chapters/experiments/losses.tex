So far all model experiments have been exclusively trained by optimizing the \textit{binary cross-entropy} loss (BCEL) function given in equation~\eqref{eq:binary-cross-entropy}.
While BCEL is by far the most popular loss function for binary classification tasks, it is still considered a suboptimal surrogate loss function for segmentation metrics such as IoU.
Alternative loss functions were discussed in~\secref{sec:segmentation-metrics}, the so-called soft loss variants being of greatest interest.
The \textit{soft Jaccard loss} given in equation~\eqref{eq:soft-jaccard-loss} and \textit{soft dice loss} given in equation~\eqref{eq:soft-dice-loss} have specifically been shown to be efficient surrogate loss functions for the IoU metric, both theoretically and empirically.
Three models have been trained and evaluated for this numerical experiment, the only difference being which loss function that has been used during training; binary cross-entropy, soft Jaccard loss, or soft dice loss.
The training procedures of these three models are visualized in \figref{fig:losses-training}.
The soft dice loss model is almost identical to the soft Jaccard loss model in behaviour and performance, and we will therefore mainly compare the BCEL model to the soft Jaccard model and ignore the soft dice model in order to avoid repetitiveness.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.495\linewidth]{metrics/lidar_dice_loss+lidar_jaccard_loss+without_rgb-validation-iou}
  \includegraphics[width=0.495\textwidth]{iou_distribution/lidar_jaccard_loss}
  \caption{%
    \textbf{Left --} Three U-Net LiDAR models trained with different loss functions.
    Binary cross-entropy model shown in \textcolor{blue}{blue}, soft Jaccard in \textcolor{orange}{orange}, and soft dice shown in \textcolor{green}{green}.
    \textbf{Right~--}~Test IoU distribution of soft Jaccard model, left \SI{6}{\percent} of data cropped.
    See caption of~\figref{fig:iou-distribution-explanation} for detailed description.
  }%
  \label{fig:losses-training}
\end{figure}

The three models presented in~\figref{fig:losses-training} start out at approximately the same point after one epoch, but the binary cross-entropy model quickly outperforms the two other models when it comes to mean validation IoU.
The soft losses seem to be \emph{worse} surrogate losses for the IoU metric rather than better ones, completely contradicting our prior beliefs.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.49\linewidth,trim={0 0.4cm 0 0.9cm},clip]{metric_correlation/without_rgb+lidar_jaccard_loss+iou}
  \textcolor{gray}{\vrule}
  \includegraphics[width=0.49\linewidth,trim={0 0.4cm 0 0.9cm},clip]{metric_correlation/without_rgb+lidar_dice_loss+iou}
  \caption{%
    Scatter plot showing the correlation between models using different losses during training.
    Both the left and right half of this figure compares model IoU against the binary cross-entropy IoU along the horizontal axis.
    Left figure half shows the soft Jaccard model on the vertical axis, while the right half shows the soft dice loss along the vertical axis.
    See caption of~\figref{fig:correlation-explanation} for detailed figure explanation.
  }
\end{figure}

\begin{figure}[H]
  \centering
  \marginlabel{\includegraphics[width=0.9\linewidth]{prediction_improvement/lidar_jaccard_loss+without_rgb/3448+0/worst.pdf}}
  \marginlabel{\includegraphics[width=0.9\linewidth]{prediction_improvement/lidar_jaccard_loss+without_rgb/3448+0/best.pdf}}
  \rule[1ex]{\textwidth}{.5pt}
  \marginlabel{\includegraphics[width=0.9\linewidth]{prediction_improvement/lidar_jaccard_loss+without_rgb/47542+0/worst.pdf}}
  \marginlabel{\includegraphics[width=0.9\linewidth]{prediction_improvement/lidar_jaccard_loss+without_rgb/47542+0/best.pdf}}
  \caption{%
    These are tiles from the training split.
  }%
\end{figure}

\begin{figure}[H]
  \centering
  \marginlabel{\includegraphics[width=0.9\linewidth]{prediction_improvement/lidar_jaccard_loss+without_rgb/20034+0/worst.pdf}}
  \marginlabel{\includegraphics[width=0.9\linewidth]{prediction_improvement/lidar_jaccard_loss+without_rgb/20034+0/best.pdf}}
  \rule[1ex]{\textwidth}{.5pt}
  \marginlabel{\includegraphics[width=0.9\linewidth]{prediction_improvement/lidar_jaccard_loss+without_rgb/25082+0/worst.pdf}}
  \marginlabel{\includegraphics[width=0.9\linewidth]{prediction_improvement/lidar_jaccard_loss+without_rgb/25082+0/best.pdf}}
  \caption{%
    These are tiles from the test split.
  }%
\end{figure}

\begin{figure}[H]
  \centering
  \marginlabel{\includegraphics[width=0.9\linewidth]{prediction_improvement/lidar_jaccard_loss+without_rgb/16016+0/best.pdf}}
  \marginlabel{\includegraphics[width=0.9\linewidth]{prediction_improvement/lidar_jaccard_loss+without_rgb/16016+0/worst.pdf}}
  \rule[1ex]{\textwidth}{.5pt}
  \marginlabel{\includegraphics[width=0.9\linewidth]{prediction_improvement/lidar_jaccard_loss+without_rgb/38663+1/best.pdf}}
  \marginlabel{\includegraphics[width=0.9\linewidth]{prediction_improvement/lidar_jaccard_loss+without_rgb/38663+1/worst.pdf}}
  \caption{%
    These are tiles from the test split.
  }%
\end{figure}
