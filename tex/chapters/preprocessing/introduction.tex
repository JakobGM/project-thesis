Our data sets need to be preprocessed in order to apply a customary machine learning pipeline.
The data preprocessing should be generalizable to different regions, data formats, data types (vector vs. raster), coordinate systems, and so on.
This will allow any potential models to be trained and/or tested against other geographic regions.

The data sets represents data over a continuous geographic area.
We must therefore define a \textit{sample space} which allows us to split the data into respective training, validation, and test sets.
Our sample space will be the respective cadastral plots defined over a given region.
The intent is to implement an algorithm which receives the geographic extent of a cadastral plot and returns a segmentation map of the buildings within the provided area.

The preprocessing is somewhat time- and space-consuming, and must therefore be performed before training and persisted to disk.
Finally, there is an intent to prevent any data loss during the preprocessing step, such as downsampling and interpolation, thus keeping the original raw features.
This allows us to experiment with different data augmentation techniques during training instead without having to preprocess the entire data set anew.
