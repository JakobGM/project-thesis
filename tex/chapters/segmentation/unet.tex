We have opted to use U-Net for segmenting building outlines, the numerical experiments being presented in~\secref{sec:experiments}.
The U-Net model has already been briefly described in the previous section and the architecture has been illustrated in~\figref{fig:unet}, but we will provide a bit more in-depth summary of the U-Net architecture here.
An alternative visual representation of the U-Net architecture is provided in~\figref{fig:unet2}.

\begin{figure}[htb]
  \includegraphics[width=0.75\textwidth]{Unet_ushape}
  \caption{%
    U-Net model architecture.
    The vertical axis is here used in order to illustrate the resolution of each module.
    Figure has been generated by modifying a \texttt{tikz} example provided in the MIT licenced \texttt{PlotNeuralNet} library available at this URL:\@
    \protect\url{https://github.com/HarisIqbal88/PlotNeuralNet}.
  }%
  \label{fig:unet2}
\end{figure}

As can be seen in~\figref{fig:unet2}, the U-Net architecture consists of four sequential \enquote{encoder modules}, each applying a set number of convolutional filters in conjunction with the ReLU activation function.
The number of trained convolutional filters in each encoder module is respectively: 64, 128, 256, and 512.
Each module ends with downsampling by the application of max-pooling of size 2.
We will use input images of resolution $256 \times 256$, thus ending up with convolutional filters of size $16 \times 16$ at the \enquote{bottleneck convolution module} where 1024 convolutional filters are trained.
The bottleneck convolution module is figuratively placed at the bottom of the U-shape in~\figref{fig:unet2}.
Each decoder block utilizes batch normalization and max-pooling dropout, although models without these building blocks will be tested in~\secref{sec:technique-experiments}.
The \enquote{decoder modules} apply transposed convolutions in order to upsample the resolution by a factor of two, the number of filters being equivalent to their respective mirror encoders, i.e.\ the encoder modules handling inputs with identical resolutions.
Four such modules are applied in order to yield a final output resolution of size $256 \times 256$.
The outputs of the mirror encoder modules are concatenated to the decoder modules in order to aid the upsampling procedure.
Finally, a sigmoid convolution with filter size \num{1} is applied in order to produce the final segmentation probabilities.
This model has been implemented using the declarative Keras API in Tensorflow v2.0 and the source code is available at the \texttt{JakobGM/project-thesis} repository on GitHub%
\footnote{%
  All source code used in order to produce and present the results in this paper are available from the following public GitHub repository: \url{https://github.com/JakobGM/project-thesis}.
  Specifically, the implementation of the U-Net architecture has been made available here: \url{https://github.com/JakobGM/project-thesis/blob/master/remsen/models.py}.
}
\todo{Note the number of trainable parameters of the final model.}
