We have chosen the U-Net architecture for segmenting building outlines and we will present numerical experiments in~\secref{sec:experiments}.
The U-Net model has already been briefly described in the previous section and the architecture has been illustrated in~\figref{fig:unet}, but we will provide a more detailed summary of the U-Net architecture here.
An alternative visual representation of the U-Net architecture is provided in~\figref{fig:unet2}.

\begin{figure}[htb]
  \includegraphics[width=0.75\textwidth]{Unet_ushape}
  \caption{%
    U-Net model architecture.
    The vertical axis denotes the resolution of the features, resulting in the U-shape of U-Net.
    Figure has been generated by modifying a \texttt{tikz} example provided in the MIT licenced \texttt{PlotNeuralNet} library available at this URL:\@
    \protect\url{https://github.com/HarisIqbal88/PlotNeuralNet}.
  }%
  \label{fig:unet2}
\end{figure}

As can be seen in~\figref{fig:unet2}, the U-Net architecture consists of four sequential \enquote{encoder modules}, each module applying a set number of convolutional filters followed by the application of the ReLU activation function.
The number of trained convolutional filters in each encoder module is respectively: 64, 128, 256, and 512.
Each module ends with a downsampling operation in form of max-pooling of size 2.
Since our input images have resolution $256 \times 256$, we end up with inputs of size $16 \times 16$ to the \enquote{bottleneck convolution module} where 1024 convolutional filters are trained.
The bottleneck convolution module is placed at the bottom of the U-shape in~\figref{fig:unet2}.
Each decoder block utilizes batch normalization and max-pooling dropout, although models without these building blocks will be tested in~\secref{sec:technique-experiments}.
The \enquote{decoder modules} apply transposed convolutions in order to upsample the resolution by a factor of two, the number of filters being equivalent to their respective \enquote{mirror encoders}, i.e.\ the encoder modules handling inputs with identical resolutions.
Four such modules are applied in order to yield a final output resolution of size $256 \times 256$, the original input resolution.
The outputs of the mirror encoder modules are concatenated to the input to the decoder modules in order to aid the upsampling procedure.
Finally, a sigmoid convolution with filter size \num{1} is applied in order to produce the final segmentation probabilities.
This model has been implemented using the declarative Keras API in Tensorflow v2.0 and the source code is available at the \texttt{JakobGM/project-thesis} repository on GitHub%
\footnote{%
  All source code used in order to produce and present the results in this paper are available from the following public GitHub repository: \url{https://github.com/JakobGM/project-thesis}.
  Specifically, the implementation of the U-Net architecture has been made available here: \url{https://github.com/JakobGM/project-thesis/blob/master/remsen/models.py}.
}.
The final network has \num{7025329} trainable parameters.
