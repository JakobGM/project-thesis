# Guidance session 6

## Notes Before Meeting

* Is `nodata = 0` really the best solution? (not really related)
* Why does validation metrics not evaluate, but checkpoints work?
* Smarter splitting of train/val/test set, using geometric sampling?
* 3 days of training before validation loss stops improving?

## Session Notes

* Often the difficult examples benefit from augmentation, we can see it on the worst offending artifacts.
* Reflect over train/val/test split instead of focusing on it
* I should reflect over how we can split the cadastre into training, validation, and test splits, but it should not be the main focus. A rectangle approach will be comparable to another region as a test set, while geometric sampling will be representative for the original region.
* How to handle `nodata` regions should not be a focus going forwards, since I can't do everything. I can write about the issue, possible choices for how to handle it, why I chose what I did, but no experimentation should be necessary. There is also a concept called "inpainting" which is relevant to this, so I should take a quick look at it.
* Validation mean IoU might be wrong, I should debug it and see if I can fix it.
* Generally, considerations are good to write down and include in the final thesis. It is useful for the "future improvements" section.
